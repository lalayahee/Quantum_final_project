{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea730c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset path: ../data/house_price.csv\n",
      "Loaded: ../data/house_price.csv shape: (318851, 26)\n",
      "Geo columns present: ['lng', 'lat']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>id</th>\n",
       "      <th>lng</th>\n",
       "      <th>lat</th>\n",
       "      <th>cid</th>\n",
       "      <th>tradetime</th>\n",
       "      <th>dom</th>\n",
       "      <th>followers</th>\n",
       "      <th>totalprice</th>\n",
       "      <th>price</th>\n",
       "      <th>...</th>\n",
       "      <th>buildingtype</th>\n",
       "      <th>constructiontime</th>\n",
       "      <th>renovationcondition</th>\n",
       "      <th>buildingstructure</th>\n",
       "      <th>ladderratio</th>\n",
       "      <th>elevator</th>\n",
       "      <th>fiveyearsproperty</th>\n",
       "      <th>subway</th>\n",
       "      <th>district</th>\n",
       "      <th>communityaverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://bj.lianjia.com/chengjiao/101084782030....</td>\n",
       "      <td>101084782030</td>\n",
       "      <td>116.475489</td>\n",
       "      <td>40.019520</td>\n",
       "      <td>1111027376244</td>\n",
       "      <td>2016-08-09</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>106</td>\n",
       "      <td>415.0</td>\n",
       "      <td>31680</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>56021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://bj.lianjia.com/chengjiao/101086012217....</td>\n",
       "      <td>101086012217</td>\n",
       "      <td>116.453917</td>\n",
       "      <td>39.881534</td>\n",
       "      <td>1111027381879</td>\n",
       "      <td>2016-07-28</td>\n",
       "      <td>903.0</td>\n",
       "      <td>126</td>\n",
       "      <td>575.0</td>\n",
       "      <td>43436</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>71539.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://bj.lianjia.com/chengjiao/101086041636....</td>\n",
       "      <td>101086041636</td>\n",
       "      <td>116.561978</td>\n",
       "      <td>39.877145</td>\n",
       "      <td>1111040862969</td>\n",
       "      <td>2016-12-11</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>48</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>52021</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>48160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://bj.lianjia.com/chengjiao/101086406841....</td>\n",
       "      <td>101086406841</td>\n",
       "      <td>116.438010</td>\n",
       "      <td>40.076114</td>\n",
       "      <td>1111043185817</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>965.0</td>\n",
       "      <td>138</td>\n",
       "      <td>297.5</td>\n",
       "      <td>22202</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>51238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://bj.lianjia.com/chengjiao/101086920653....</td>\n",
       "      <td>101086920653</td>\n",
       "      <td>116.428392</td>\n",
       "      <td>39.886229</td>\n",
       "      <td>1111027381174</td>\n",
       "      <td>2016-08-28</td>\n",
       "      <td>927.0</td>\n",
       "      <td>286</td>\n",
       "      <td>392.0</td>\n",
       "      <td>48396</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1960</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>62588.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url            id  \\\n",
       "0  https://bj.lianjia.com/chengjiao/101084782030....  101084782030   \n",
       "1  https://bj.lianjia.com/chengjiao/101086012217....  101086012217   \n",
       "2  https://bj.lianjia.com/chengjiao/101086041636....  101086041636   \n",
       "3  https://bj.lianjia.com/chengjiao/101086406841....  101086406841   \n",
       "4  https://bj.lianjia.com/chengjiao/101086920653....  101086920653   \n",
       "\n",
       "          lng        lat            cid   tradetime     dom  followers  \\\n",
       "0  116.475489  40.019520  1111027376244  2016-08-09  1464.0        106   \n",
       "1  116.453917  39.881534  1111027381879  2016-07-28   903.0        126   \n",
       "2  116.561978  39.877145  1111040862969  2016-12-11  1271.0         48   \n",
       "3  116.438010  40.076114  1111043185817  2016-09-30   965.0        138   \n",
       "4  116.428392  39.886229  1111027381174  2016-08-28   927.0        286   \n",
       "\n",
       "   totalprice  price  ...  buildingtype constructiontime renovationcondition  \\\n",
       "0       415.0  31680  ...           1.0             2005                   3   \n",
       "1       575.0  43436  ...           1.0             2004                   4   \n",
       "2      1030.0  52021  ...           4.0             2005                   3   \n",
       "3       297.5  22202  ...           1.0             2008                   1   \n",
       "4       392.0  48396  ...           4.0             1960                   2   \n",
       "\n",
       "   buildingstructure ladderratio elevator  fiveyearsproperty subway  district  \\\n",
       "0                  6       0.217      1.0                0.0    1.0         7   \n",
       "1                  6       0.667      1.0                1.0    0.0         7   \n",
       "2                  6       0.500      1.0                0.0    0.0         7   \n",
       "3                  6       0.273      1.0                0.0    0.0         6   \n",
       "4                  2       0.333      0.0                1.0    1.0         1   \n",
       "\n",
       "   communityaverage  \n",
       "0           56021.0  \n",
       "1           71539.0  \n",
       "2           48160.0  \n",
       "3           51238.0  \n",
       "4           62588.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Quick import + checks\n",
    "required = [\"pandas\",\"numpy\"]\n",
    "import importlib, sys\n",
    "missing = [p for p in required if importlib.util.find_spec(p) is None]\n",
    "if missing:\n",
    "    print(\"Missing packages:\", missing)\n",
    "    print(\"Install in notebook: %pip install \" + \" \".join(missing) + \" (or run in terminal)\")\n",
    "    raise SystemExit(\"Install missing packages and re-run\")\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "# robust file lookup (try data_path if present, common variants, and a glob search)\n",
    "import os, glob\n",
    "\n",
    "candidates = []\n",
    "if 'data_path' in globals() and data_path:\n",
    "    candidates.append(data_path)\n",
    "# common path variants\n",
    "candidates += [\n",
    "    \"../data/house_price.csv\",\n",
    "]\n",
    "# search project for any csvs with 'house' in the name\n",
    "candidates += glob.glob(\"**/*house*.csv\", recursive=True)\n",
    "\n",
    "# dedupe keeping order\n",
    "seen = set()\n",
    "candidates = [p for p in candidates if not (p in seen or seen.add(p))]\n",
    "\n",
    "found = next((p for p in candidates if os.path.exists(p)), None)\n",
    "if found is None:\n",
    "    raise FileNotFoundError(f\"No house_price csv found. Searched candidates: {candidates}\")\n",
    "\n",
    "path = found\n",
    "print(\"Using dataset path:\", path)\n",
    "\n",
    "# read with fallback encoding\n",
    "try:\n",
    "    df = pd.read_csv(path, low_memory=False, encoding=\"utf-8\")\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(path, low_memory=False, encoding=\"latin1\")\n",
    "\n",
    "# normalize column names and canonicalize geo cols\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "if \"longitude\" in df.columns and \"lng\" not in df.columns:\n",
    "    df[\"lng\"] = pd.to_numeric(df[\"longitude\"].astype(str).str.replace(r\"[^0-9.-]\", \"\", regex=True), errors=\"coerce\")\n",
    "if \"latitude\" in df.columns and \"lat\" not in df.columns:\n",
    "    df[\"lat\"] = pd.to_numeric(df[\"latitude\"].astype(str).str.replace(r\"[^0-9.-]\", \"\", regex=True), errors=\"coerce\")\n",
    "\n",
    "print(\"Loaded:\", path, \"shape:\", df.shape)\n",
    "print(\"Geo columns present:\", [c for c in [\"lng\",\"lat\",\"longitude\",\"latitude\"] if c in df.columns])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9ce4641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target defined using: totalprice median: 294.0\n",
      "Geo columns preserved: ['lng', 'lat']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Stage 1: Basic preprocessing\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "# drop obvious irrelevant columns if they exist\n",
    "drop_cols = [c for c in ['url','id','cid','link'] if c in df.columns]\n",
    "if drop_cols:\n",
    "    df = df.drop(columns=drop_cols)\n",
    "# canonicalize geo column names and preserve latitude/longitude\n",
    "# create canonical `lng`/`lat` if raw columns exist (keep numeric)\n",
    "if 'longitude' in df.columns and 'lng' not in df.columns:\n",
    "    df['lng'] = pd.to_numeric(df['longitude'].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce')\n",
    "if 'latitude' in df.columns and 'lat' not in df.columns:\n",
    "    df['lat'] = pd.to_numeric(df['latitude'].astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce')\n",
    "# list of geo columns we want to keep\n",
    "geo_cols = [c for c in ['lng','lat','longitude','latitude'] if c in df.columns]\n",
    "# convert common price/area columns to numeric (include geo cols if present)\n",
    "def to_numeric_col(s):\n",
    "    return pd.to_numeric(s.astype(str).str.replace(r'[^0-9.-]', '', regex=True), errors='coerce')\n",
    "\n",
    "for col in ['totalprice','price','square','area','buildingarea','lng','lat','longitude','latitude']:\n",
    "    if col in df.columns:\n",
    "        df[col] = to_numeric_col(df[col])\n",
    "\n",
    "\n",
    "# create binary target using median totalPrice if available (fall back to price)\n",
    "\n",
    "target_col = 'totalprice' if 'totalprice' in df.columns else ('price' if 'price' in df.columns else None)\n",
    "if target_col is None:\n",
    "    raise RuntimeError(\"No price column found. Add totalPrice or price to proceed.\")\n",
    "median_price = df[target_col].median()\n",
    "df['target'] = (df[target_col] >= median_price).astype(int)\n",
    "print(\"Target defined using:\", target_col, \"median:\", median_price)\n",
    "# confirm geo columns present (if any)\n",
    "print(\"Geo columns preserved:\", geo_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "550d6076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After imputation shape: (318825, 26)\n",
      "Geo columns after imputation: {'lng': 0, 'lat': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_8396\\1184988710.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].fillna(df[c].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Stage 2: Missing values, dtypes, derived features\n",
    "# drop exact duplicates\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# impute numeric columns with median, categorical with mode\n",
    "num_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "# exclude geo columns from the generic numeric imputation (handle them separately)\n",
    "num_impute_cols = [c for c in num_cols if c not in geo_cols]\n",
    "# exclude geo columns from categorical imputation too\n",
    "cat_cols = df.select_dtypes(include=['object','category']).columns.difference(['address','title'] + geo_cols).tolist()\n",
    "\n",
    "for c in num_impute_cols:\n",
    "    if df[c].isna().any():\n",
    "        df[c].fillna(df[c].median(), inplace=True)\n",
    "# For geo cols, fill small gaps with median to avoid row loss in downstream steps (optional)\n",
    "for c in geo_cols:\n",
    "    if c in df.columns and df[c].isna().any():\n",
    "        df[c].fillna(df[c].median(), inplace=True)\n",
    "\n",
    "for c in cat_cols:\n",
    "    if df[c].isna().any():\n",
    "        df[c].fillna(df[c].mode().iloc[0] if not df[c].mode().empty else \"missing\", inplace=True)\n",
    "\n",
    "# datetime parsing example (if present)\n",
    "for date_col in ['publish_time','listing_date','built_year']:\n",
    "    if date_col in df.columns:\n",
    "        try:\n",
    "            df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# derived features (defensive checks)\n",
    "if 'square' in df.columns and target_col in df.columns:\n",
    "    df['price_per_sqm'] = df[target_col] / df['square']\n",
    "    df['log_price'] = (df[target_col].clip(lower=1)).apply(np.log)\n",
    "\n",
    "# age of building (if build year or date available)\n",
    "if 'built_year' in df.columns and pd.api.types.is_datetime64_any_dtype(df['built_year']):\n",
    "    df['building_age'] = pd.Timestamp.now().year - df['built_year'].dt.year\n",
    "elif 'built_year' in df.columns:\n",
    "    df['building_age'] = pd.to_numeric(df['built_year'], errors='coerce').apply(lambda x: pd.Timestamp.now().year - x if pd.notna(x) else np.nan)\n",
    "    df['building_age'].fillna(df['building_age'].median(), inplace=True)\n",
    "\n",
    "print(\"After imputation shape:\", df.shape)\n",
    "print(\"Geo columns after imputation:\", {c: df[c].isna().sum() for c in geo_cols if c in df.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5070fda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after encoding: 51\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Stage 3: Outliers and encoding\n",
    "num_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "# exclude target columns and geo columns from clipping\n",
    "num_cols = [c for c in num_cols if c not in [target_col,'target'] + geo_cols]\n",
    "for c in num_cols:\n",
    "    qlow, qhigh = df[c].quantile(0.01), df[c].quantile(0.99)\n",
    "    if pd.notna(qlow) and pd.notna(qhigh) and qlow < qhigh:\n",
    "        df[c] = df[c].clip(qlow, qhigh)\n",
    "\n",
    "# select top categorical cols by cardinality (small ones for get_dummies)\n",
    "# ensure geo columns aren't treated as categoricals\n",
    "cat_cols = [c for c in df.select_dtypes(include=['object','category']).nunique().sort_values().index.tolist() if c not in geo_cols]\n",
    "cat_to_encode = [c for c in cat_cols if df[c].nunique() <= 20][:6]  # keep up to 6 small-cardinal cols\n",
    "if cat_to_encode:\n",
    "    df = pd.get_dummies(df, columns=cat_to_encode, drop_first=True)\n",
    "\n",
    "print(\"Columns after encoding:\", len(df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53876336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features selected : ['log_price', 'price_per_sqm', 'price', 'square', 'communityaverage', 'dom', 'ladderratio', 'renovationcondition', 'followers', 'elevator']\n",
      "Included geo columns (if present): ['lng', 'lat']\n",
      "Saved final dataset to: c:\\Year 4\\Quantum\\Quantum_final_project\\classical_ml\\data\\house_price_top10.csv shape: (318825, 14)\n",
      "File exists: True size(bytes): 33766585\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Stage 4: Feature selection (top 10)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# prepare feature matrix\n",
    "features = df.select_dtypes(include=[np.number]).drop(columns=[target_col,'target'], errors='ignore').columns.tolist()\n",
    "\n",
    "# corr ranking (abs correlation with continuous price if present)\n",
    "corr_rank = pd.Series(0, index=features)\n",
    "if target_col in df.columns:\n",
    "    corr_vals = df[features + [target_col]].corr()[target_col].abs().drop(target_col)\n",
    "    corr_rank = corr_vals.rank(ascending=False)\n",
    "\n",
    "# RandomForest feature importance on binary target\n",
    "X = df[features].fillna(0)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "imp = pd.Series(rf.feature_importances_, index=features)\n",
    "imp_rank = imp.rank(ascending=False)\n",
    "\n",
    "# combined rank average\n",
    "combined_rank = (corr_rank.rank() + imp_rank.rank()) / 2\n",
    "\n",
    "# initial top candidates\n",
    "top10 = combined_rank.sort_values().head(10).index.tolist()\n",
    "\n",
    "# ensure longitude/latitude are included among the top 10\n",
    "geo_required = [c for c in ['lng','lat'] if c in df.columns]\n",
    "for g in geo_required:\n",
    "    if g not in top10 and g in combined_rank.index:\n",
    "        top10.append(g)\n",
    "\n",
    "# if we added geo cols and exceeded 10, drop the worst-ranked features among the current selection\n",
    "if len(top10) > 10:\n",
    "    ranks = combined_rank.loc[top10]\n",
    "    to_drop = ranks.sort_values(ascending=False).head(len(top10) - 10).index.tolist()\n",
    "    top10 = [f for f in top10 if f not in to_drop]\n",
    "\n",
    "print(\"Top 10 features selected :\", top10)\n",
    "\n",
    "# create final dataframe with those features + target, but keep longitude/latitude if present\n",
    "geo_cols = [c for c in ['lng','lat','longitude','latitude'] if c in df.columns]\n",
    "final_cols = top10.copy()\n",
    "for c in geo_cols:\n",
    "    if c not in final_cols:\n",
    "        final_cols.append(c)\n",
    "# add target columns\n",
    "if target_col in df.columns:\n",
    "    final_cols += [target_col, 'target']\n",
    "else:\n",
    "    final_cols += ['target']\n",
    "final_df = df[final_cols].copy()\n",
    "print(\"Included geo columns (if present):\", geo_cols)\n",
    "\n",
    "# save (ensure directory exists) — save explicitly into repo `data/` folder\n",
    "out_dir = os.path.abspath(os.path.join(os.getcwd(), \"data\"))\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_path = os.path.join(out_dir, \"house_price_top10.csv\")\n",
    "final_df.to_csv(out_path, index=False)\n",
    "print(\"Saved final dataset to:\", out_path, \"shape:\", final_df.shape)\n",
    "# quick verification\n",
    "import os as _os\n",
    "print(\"File exists:\", _os.path.exists(out_path), \"size(bytes):\", _os.path.getsize(out_path) if _os.path.exists(out_path) else \"n/a\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
